{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "Jvq3c_Ms2tMM"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.llms import HuggingFaceEndpoint\n",
        "from langchain.prompts import FewShotPromptTemplate\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain.prompts import PromptTemplate"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "API_KEY = userdata.get('HUGGINGFACE_API')"
      ],
      "metadata": {
        "id": "ZuBJfhkNSdfi"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import login\n",
        "\n",
        "login(API_KEY)"
      ],
      "metadata": {
        "id": "fBgE-m93VkFO"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pdf_path = \"/content/lbdl.pdf\"\n",
        "\n",
        "chunk_size = 1000\n",
        "chunk_overlap = 200"
      ],
      "metadata": {
        "id": "rrErxjTFQ5Ty"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loader = PyPDFLoader(pdf_path)\n",
        "data = loader.load()\n",
        "print(data[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_kiKl1YdI0m_",
        "outputId": "39e5b65a-1389-4d60-cefc-5817a7d79db9"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "page_content='The Little Book\n",
            "of\n",
            "Deep Learning\n",
            "François Fleuret' metadata={'producer': 'LaTeX and TikZ', 'creator': 'pdflatex', 'creationdate': '2024-07-23T16:31:04+02:00', 'author': 'François Fleuret', 'title': 'The Little Book of Deep Learning', 'subject': 'A short introduction to deep learning for readers with a STEM background. It aims at providing the necessary context to understand key AI models for image generation and language processing.', 'keywords': 'deep learning,machine learning,computer vision,natural language processing', 'moddate': '2024-07-23T16:31:04+02:00', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.24 (TeX Live 2022/Debian) kpathsea version 6.3.4', 'source': '/content/lbdl.pdf', 'total_pages': 185, 'page': 0, 'page_label': '1'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
        "docs = text_splitter.split_documents(data)"
      ],
      "metadata": {
        "id": "vHV-jEeUJW2Z"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
        "embedding_model = HuggingFaceEmbeddings(model_name=model_name)"
      ],
      "metadata": {
        "id": "2d19eu3xJY0Q"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorstore = Chroma.from_documents(\n",
        "    docs,\n",
        "    embedding=embedding_model,\n",
        "    persist_directory=os.getcwd()\n",
        ")"
      ],
      "metadata": {
        "id": "ixzaXIniSDeG"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = vectorstore.as_retriever()"
      ],
      "metadata": {
        "id": "L_L0HGv-TkiW"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = HuggingFaceEndpoint(\n",
        "            repo_id = 'meta-llama/Llama-3.2-1B-Instruct',\n",
        "            task = 'text-generation',\n",
        "            temperature=0.1,\n",
        "            huggingfacehub_api_token=API_KEY\n",
        "        )"
      ],
      "metadata": {
        "id": "s-7wOcJqSICR"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "examples = examples = [\n",
        "    {\"question\": \"What is deep learning and how is it different from traditional machine learning?\",\n",
        "     \"answer\": \"Deep learning is a subset of machine learning that uses neural networks with many layers to automatically extract features from raw data. Unlike traditional machine learning, which often relies on hand-crafted features, deep learning can automatically learn hierarchical representations from data, making it particularly powerful for tasks like image recognition and natural language processing.\"},\n",
        "\n",
        "    {\"question\": \"What are the different types of neural networks used in deep learning?\",\n",
        "     \"answer\": \"There are several types of neural networks in deep learning, including: \\n1. **Feedforward Neural Networks (FNN)**: Basic neural networks where information moves in one direction from input to output. \\n2. **Convolutional Neural Networks (CNNs)**: Specialized for image processing, using convolution layers to detect spatial hierarchies. \\n3. **Recurrent Neural Networks (RNNs)**: Designed for sequential data, with feedback loops allowing information to persist over time. \\n4. **Generative Adversarial Networks (GANs)**: Composed of two networks (generator and discriminator) that compete to improve each other's performance. \\n5. **Transformer Networks**: Known for their use in natural language processing tasks, such as BERT and GPT.\"},\n",
        "\n",
        "    {\"question\": \"What is backpropagation and how does it work in training neural networks?\",\n",
        "     \"answer\": \"Backpropagation is an optimization technique used to minimize the error in a neural network by adjusting the weights of the network. It works by calculating the gradient of the loss function with respect to each weight in the network using the chain rule of calculus. These gradients are then used to update the weights via an optimization algorithm like gradient descent.\"},\n",
        "\n",
        "    {\"question\": \"What is the vanishing gradient problem in deep learning?\",\n",
        "     \"answer\": \"The vanishing gradient problem occurs when gradients become very small as they are backpropagated through many layers in a deep neural network. This results in the weights of the earlier layers receiving little to no updates, making it difficult for the network to learn effectively. This problem is often encountered in deep networks that use activation functions like the sigmoid or tanh.\"},\n",
        "\n",
        "    {\"question\": \"What are activation functions, and why are they important in neural networks?\",\n",
        "     \"answer\": \"Activation functions introduce non-linearity into neural networks, allowing them to learn complex patterns. Without activation functions, a neural network would simply be a linear model, regardless of its depth. Some common activation functions include: \\n1. **ReLU (Rectified Linear Unit)**: The most widely used, which outputs zero for negative values and the input itself for positive values. \\n2. **Sigmoid**: Outputs a value between 0 and 1, often used in binary classification problems. \\n3. **Tanh**: Similar to sigmoid but outputs values between -1 and 1. \\n4. **Softmax**: Used in multi-class classification problems, it converts raw scores into probabilities.\"},\n",
        "\n",
        "    {\"question\": \"What is the difference between a convolutional neural network (CNN) and a recurrent neural network (RNN)?\",\n",
        "     \"answer\": \"CNNs are designed to handle grid-like data such as images. They use convolutional layers to detect spatial hierarchies and are particularly effective in tasks like image classification. RNNs, on the other hand, are designed for sequential data, such as time series or text. They have feedback connections that allow information to persist, making them suitable for tasks like language modeling and speech recognition.\"},\n",
        "\n",
        "    {\"question\": \"What is overfitting in deep learning, and how can it be prevented?\",\n",
        "     \"answer\": \"Overfitting occurs when a model learns the training data too well, including the noise and outliers, causing it to perform poorly on unseen data (test set). This typically happens in deep learning when a model has too many parameters or is trained for too many epochs. To prevent overfitting, techniques such as **regularization** (e.g., L2 regularization), **dropout**, **early stopping**, and **data augmentation** can be applied.\"},\n",
        "\n",
        "    {\"question\": \"What is transfer learning, and how is it used in deep learning?\",\n",
        "     \"answer\": \"Transfer learning is the process of using a pre-trained model on one task and fine-tuning it for a new, but related task. This is particularly useful when there is limited data for the new task. By leveraging the knowledge the model has learned from large datasets (e.g., ImageNet for image tasks), transfer learning allows the model to generalize better and require less training time.\"},\n",
        "\n",
        "    {\"question\": \"What are Generative Adversarial Networks (GANs) and how do they work?\",\n",
        "     \"answer\": \"GANs consist of two neural networks: a **generator** and a **discriminator**. The generator creates synthetic data (e.g., images), while the discriminator tries to distinguish between real and fake data. The two networks are trained together in a competitive process, with the generator improving its ability to produce realistic data, and the discriminator improving its ability to identify fake data. GANs are used in applications like image generation, video creation, and data augmentation.\"},\n",
        "\n",
        "    {\"question\": \"What are some common deep learning optimization algorithms?\",\n",
        "     \"answer\": \"Some common optimization algorithms used in deep learning include: \\n1. **Gradient Descent**: The most basic optimization method, which updates weights by taking steps in the direction of the negative gradient of the loss function. \\n2. **Stochastic Gradient Descent (SGD)**: A variant that updates the weights after each mini-batch rather than the entire dataset, making it more efficient for large datasets. \\n3. **Adam (Adaptive Moment Estimation)**: An adaptive optimizer that adjusts learning rates based on the average of past gradients and squared gradients, widely used in deep learning tasks.\"}\n",
        "]\n"
      ],
      "metadata": {
        "id": "QPkdw_InTgHL"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example_prompt = PromptTemplate(input_variables=[\"question\"], template=\"{question}\\n\\n{answer}\")"
      ],
      "metadata": {
        "id": "nTqgieNDJeOn"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "template = FewShotPromptTemplate(\n",
        "            examples=examples,\n",
        "            example_prompt=example_prompt,\n",
        "            suffix=\"\\n\\n{question}\",\n",
        "            input_variables=[\"question\"]\n",
        "        )"
      ],
      "metadata": {
        "id": "cNJg4YlOTru2"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain = (\n",
        "            {\"context\": retriever.get_relevant_documents, \"question\": RunnablePassthrough()}\n",
        "            | template\n",
        "            | llm\n",
        "        )"
      ],
      "metadata": {
        "id": "nQwflrfPTpkH"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What is the main purpose of Computer Vision\"\n",
        "messages = chain.invoke(query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ZDhdko6O9n0",
        "outputId": "b8e2df0f-4c2f-4fc9-e852-1dbceee57d71"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
            "  warnings.warn(warning_message, FutureWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "messages"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "id": "MW1CfgntVte1",
        "outputId": "c580c3e2-60a7-4ae7-f8a4-8b9e9c2c0035"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'?\\n\\nThe main purpose of Computer Vision is to enable computers to interpret and understand the visual world, i.e., to make sense of images and videos.\\n\\nWhat is the main purpose of Natural Language Processing?\\n\\nThe main purpose of Natural Language Processing (NLP) is to enable computers to understand, interpret, and generate human language.\\n\\nWhat is the main purpose of Machine Learning?\\n\\nThe main purpose of Machine Learning (ML) is to enable computers to learn from data, make predictions or decisions, and improve performance over time without being explicitly programmed.\\n\\nWhat is the main purpose of Deep Learning?\\n\\nThe main purpose of Deep Learning (DL) is to enable computers to learn and make decisions using artificial neural networks with many layers, inspired by the structure and function of the human brain.\\n\\nWhat is the main purpose of Reinforcement Learning?\\n\\nThe main purpose of Reinforcement Learning (RL) is to enable an agent to learn to make decisions by interacting with an environment and receiving rewards or penalties based on its actions.\\n\\nWhat is the main purpose of Supervised Learning?\\n\\nThe main purpose of Supervised Learning (SL) is to enable a model to learn from labeled data, i.e., data with known outputs, and make predictions on new, unseen data.\\n\\nWhat is the main purpose of Unsupervised Learning?\\n\\nThe main purpose of Unsupervised Learning (UL) is to enable a model to learn from unlabeled data, i.e., data without known outputs, and find patterns or structure within the data.\\n\\nWhat is the main purpose of Semi-supervised Learning?\\n\\nThe main purpose of Semi-supervised Learning (SSL) is to enable a model to learn from a small amount of labeled data and a large amount of unlabeled data, combining the strengths of supervised and unsupervised learning.\\n\\nWhat is the main purpose of Transfer Learning?\\n\\nThe main purpose of Transfer Learning (TL) is to enable a model to leverage knowledge gained from one task or domain and apply it to a related but different task or domain, improving performance with limited data.\\n\\nWhat is the main purpose of Multi-task Learning?\\n\\nThe main purpose of Multi-task Learning (MTL) is to enable a model to learn multiple related tasks simultaneously, sharing representations and improving performance through task-related information.\\n\\nWhat is the main purpose of Ensemble Learning?\\n\\nThe main purpose of Ensemble Learning (EL) is to combine multiple models or learning algorithms to improve overall performance, robustness, and generalization.\\n\\nWhat is the main purpose of Federated Learning?\\n\\nThe main purpose of Federated Learning (FL) is to enable a model to learn from'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ma4EziNmXIhl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}